
from google.colab import drive
drive.mount('/content/drive')


!pip install ultralytics supervision roboflow


import torch
import numpy as np
from ultralytics import YOLO
import supervision as sv
import cv2
from pathlib import Path






# Initialized device
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {DEVICE}")

# Load model v1
model_path = "/content/drive/MyDrive/pizza_project/training_results/pizza_detector_stable/weights/best.pt"
model = YOLO(model_path)
model.to(DEVICE)

print("Model loaded successfully!")
print(f"Model metrics: Precision 0.988, Recall 0.545, mAP50-95 0.6")






import os
import numpy as np
import cv2

def get_video_resolution(video_path):
    """Get video resolution safely"""
    try:
        cap = cv2.VideoCapture(video_path)
        if cap.isOpened():
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()
            return (width, height)
        else:
            return None
    except Exception as e:
        print(f"Error reading video {video_path}: {e}")
        return None

def scale_polygon_coordinates(polygon, original_size, target_size):
    """Scale polygon coordinates from PolygonZone resolution to video resolution"""
    scale_x = target_size[0] / original_size[0]
    scale_y = target_size[1] / original_size[1]

    scaled_polygon = polygon.copy().astype(float)
    scaled_polygon[:, 0] *= scale_x  # Scale X coordinates
    scaled_polygon[:, 1] *= scale_y  # Scale Y coordinates

    return scaled_polygon.astype(int)

def auto_detect_camera_videos_with_scaling(base_path):
    """T·ª± ƒë·ªông detect video files v√† scale polygon coordinates"""
    camera_configs = {}

    # PolygonZone tool resolution (theo b·ªá h·∫° confirm)
    POLYGONZONE_RESOLUTION = (1280, 720)

    # Original zone polygons t·ª´ PolygonZone tool
    zone_polygons_original = {
        "CAM_01": np.array([[66, 431], [432, 468], [429, 540], [389, 542], [358, 716], [10, 712]]),
        "CAM_02": np.array([[830, 428], [643, 709], [1067, 717], [1172, 400], [1096, 370], [1055, 483]]),
        "CAM_03": np.array([[562, 716], [936, 267], [1023, 296], [1094, 126], [1239, 186], [1038, 709]]),
        "CAM_04": np.array([[236, 202], [262, 200], [262, 212], [494, 259], [909, 715], [270, 715]]),
        "CAM_05": np.array([[373, 5], [392, 182], [1038, 110], [997, 0]]),
        "CAM_06": np.array([[881, 257], [208, 713], [891, 715], [1003, 278]])
    }

    print("=== AUTO-DETECTING CAMERAS AND SCALING ZONES ===")

    for cam_num in range(1, 7):  # CAM_01 ƒë·∫øn CAM_06
        cam_id = f"CAM_{cam_num:02d}"
        cam_folder = os.path.join(base_path, "raw_data", cam_id)

        print(f"\n{cam_id}:")

        if os.path.exists(cam_folder):
            # T√¨m video files
            video_files = [f for f in os.listdir(cam_folder)
                          if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]

            if video_files:
                # L·∫•y video file ƒë·∫ßu ti√™n
                video_file = sorted(video_files)[0]
                video_path = os.path.join(cam_folder, video_file)

                # Get video resolution
                video_resolution = get_video_resolution(video_path)

                if video_resolution:
                    print(f"  ‚úì Video: {video_file}")
                    print(f"  ‚úì Resolution: {video_resolution}")

                    # Scale polygon coordinates
                    if cam_id in zone_polygons_original:
                        original_polygon = zone_polygons_original[cam_id]
                        scaled_polygon = scale_polygon_coordinates(
                            original_polygon,
                            POLYGONZONE_RESOLUTION,
                            video_resolution
                        )

                        print(f"  ‚úì Zone scaled: {len(scaled_polygon)} points")
                        print(f"    Original: {original_polygon[0]} -> {original_polygon[-1]}")
                        print(f"    Scaled: {scaled_polygon[0]} -> {scaled_polygon[-1]}")

                        # Create config
                        camera_configs[cam_id] = {
                            "source_video_path": video_path,
                            "target_video_path": f"/content/drive/MyDrive/pizza_project/output_videos/{cam_id}_processed.mp4",
                            "frame_resolution_wh": video_resolution,
                            "zone_polygon": scaled_polygon,
                            "original_polygon": original_polygon,  # Keep for reference
                            "scale_factors": (
                                video_resolution[0] / POLYGONZONE_RESOLUTION[0],
                                video_resolution[1] / POLYGONZONE_RESOLUTION[1]
                            )
                        }
                    else:
                        print(f"  ‚úó No zone polygon defined for {cam_id}")
                else:
                    print(f"  ‚úó Cannot read video resolution")
            else:
                print(f"  ‚úó No video files found")
        else:
            print(f"  ‚úó Directory not found: {cam_folder}")

    return camera_configs

# Ch·∫°y auto-detection v·ªõi scaling
base_path = "/content/drive/MyDrive/pizza_project"
CAMERA_CONFIGS = auto_detect_camera_videos_with_scaling(base_path)

# Verify final configurations
print("\n" + "="*60)
print("FINAL CAMERA CONFIGURATIONS")
print("="*60)

for cam_id, config in CAMERA_CONFIGS.items():
    video_exists = os.path.exists(config['source_video_path'])
    zone_defined = config['zone_polygon'] is not None

    print(f"\n{cam_id}:")
    print(f"  Video: {os.path.basename(config['source_video_path'])} {'‚úì' if video_exists else '‚úó'}")
    print(f"  Resolution: {config['frame_resolution_wh']}")
    print(f"  Zone: {'‚úì' if zone_defined else '‚úó'} ({len(config['zone_polygon']) if zone_defined else 0} points)")
    print(f"  Scale factors: X={config['scale_factors'][0]:.2f}, Y={config['scale_factors'][1]:.2f}")

print(f"\n‚úì Total cameras configured: {len(CAMERA_CONFIGS)}")






def test_scaled_zone_visualization(cam_id, frame_number=100):
    """Test xem zone ƒë√£ ƒë∆∞·ª£c scale ƒë√∫ng ch∆∞a"""
    if cam_id not in CAMERA_CONFIGS:
        print(f"{cam_id} not found in configs")
        return

    config = CAMERA_CONFIGS[cam_id]
    cap = cv2.VideoCapture(config['source_video_path'])

    # ƒêi ƒë·∫øn frame test
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
    ret, frame = cap.read()

    if ret:
        # V·∫Ω scaled zone
        polygon = config['zone_polygon']
        cv2.polylines(frame, [polygon], True, (0, 255, 0), 5)

        # Add info text
        cv2.putText(frame, f"{cam_id} - Scaled Zone Test", (50, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        cv2.putText(frame, f"Resolution: {config['frame_resolution_wh']}", (50, 100),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # Save test image
        output_path = f"/content/drive/MyDrive/pizza_project/zone_test_{cam_id}.jpg"
        cv2.imwrite(output_path, frame)
        print(f"‚úì Zone test saved: {output_path}")

    cap.release()


# Test zone for CAM_01 
test_scaled_zone_visualization("CAM_01")
test_scaled_zone_visualization("CAM_02")
test_scaled_zone_visualization("CAM_03")
test_scaled_zone_visualization("CAM_04")
test_scaled_zone_visualization("CAM_05")
test_scaled_zone_visualization("CAM_06")





import time
import numpy as np
import cv2
from ultralytics import YOLO
from collections import defaultdict
import os

class SalesTrackingProcessor:
    def __init__(self, camera_configs, model):
        self.camera_configs = camera_configs
        self.model = model

        # Simplified tracking without supervision annotators
        self.active_tracks = {}  # {track_id: {"bbox": bbox, "last_seen": frame, "confidence": conf}}
        self.track_history = {}  # {track_id: [list of center points]}
        self.next_track_id = 1

        # Sales tracking
        self.pizza_states = {}
        self.sales_counts = {cam: {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0} for cam in camera_configs}
        self.dispatch_threshold = 30  # 0.5 minutes

        # Tracking parameters
        self.max_missing_frames = 30  # 1 second at 30fps
        self.iou_threshold = 0.3
        self.confidence_threshold = 0.25

        self.frame_count = 0
        self.fps = 30

    def is_in_zone(self, center_point, zone_polygon):
        """Check if point is inside the defined zone"""
        return cv2.pointPolygonTest(zone_polygon, center_point, False) >= 0

    def calculate_iou(self, box1, box2):
        """Calculate Intersection over Union"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2

        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)

        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0

        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0.0

    def simple_tracking(self, detections):
        """Simple tracking algorithm without supervision dependencies - FIXED"""
        # Fix: Check if detections has xyxy attribute and use its length
        if not hasattr(detections, 'xyxy') or len(detections.xyxy) == 0:
            # Update missing frames for all tracks
            for track_id in list(self.active_tracks.keys()):
                self.active_tracks[track_id]["missing_frames"] = self.active_tracks[track_id].get("missing_frames", 0) + 1
                if self.active_tracks[track_id]["missing_frames"] > self.max_missing_frames:
                    del self.active_tracks[track_id]
            return []

        # Extract detection data
        bboxes = detections.xyxy
        confidences = detections.confidence

        # Match detections to existing tracks
        matched_tracks = []
        unmatched_detections = list(range(len(bboxes)))

        for track_id, track_data in list(self.active_tracks.items()):
            best_iou = 0
            best_detection_idx = -1

            for det_idx in unmatched_detections:
                iou = self.calculate_iou(track_data["bbox"], bboxes[det_idx])
                if iou > best_iou and iou > self.iou_threshold:
                    best_iou = iou
                    best_detection_idx = det_idx

            if best_detection_idx >= 0:
                # Update existing track
                self.active_tracks[track_id] = {
                    "bbox": bboxes[best_detection_idx],
                    "confidence": confidences[best_detection_idx],
                    "last_seen": self.frame_count,
                    "missing_frames": 0
                }
                matched_tracks.append((track_id, best_detection_idx))
                unmatched_detections.remove(best_detection_idx)
            else:
                # Track not matched, increment missing frames
                self.active_tracks[track_id]["missing_frames"] = self.active_tracks[track_id].get("missing_frames", 0) + 1
                if self.active_tracks[track_id]["missing_frames"] > self.max_missing_frames:
                    del self.active_tracks[track_id]

        # Create new tracks for unmatched detections
        for det_idx in unmatched_detections:
            if confidences[det_idx] > self.confidence_threshold:
                self.active_tracks[self.next_track_id] = {
                    "bbox": bboxes[det_idx],
                    "confidence": confidences[det_idx],
                    "last_seen": self.frame_count,
                    "missing_frames": 0
                }
                matched_tracks.append((self.next_track_id, det_idx))
                self.next_track_id += 1

        # Return tracked detections
        tracked_detections = []
        for track_id, det_idx in matched_tracks:
            bbox = bboxes[det_idx]
            conf = confidences[det_idx]
            tracked_detections.append({
                "track_id": track_id,
                "bbox": bbox,
                "confidence": conf,
                "center": ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
            })

        return tracked_detections

    def update_pizza_sales_tracking(self, cam_id, tracked_detections, zone_polygon, current_timestamp):
        """Sales tracking logic"""
        current_tracks_in_zone = set()
        current_tracks_detected = set()

        # Process tracked detections
        for detection in tracked_detections:
            track_id = detection["track_id"]
            center = detection["center"]
            in_zone = self.is_in_zone(center, zone_polygon)

            current_tracks_detected.add(track_id)

            if in_zone:
                current_tracks_in_zone.add(track_id)

                # Pizza entered zone
                if track_id not in self.pizza_states:
                    self.pizza_states[track_id] = {
                        "status": "in_zone",
                        "enter_time": current_timestamp,
                        "exit_time": None,
                        "cam_id": cam_id
                    }
                    print(f"üçï Pizza #{track_id} entered staging zone at {current_timestamp:.1f}s")

                # Pizza returned to zone
                elif self.pizza_states[track_id]["status"] == "pending_dispatch":
                    self.pizza_states[track_id]["status"] = "in_zone"
                    self.pizza_states[track_id]["exit_time"] = None
                    self.sales_counts[cam_id]["pending_dispatch"] -= 1
                    print(f"‚Ü©Ô∏è Pizza #{track_id} returned to zone - dispatch cancelled")

        # Check for pizzas that left the zone
        for track_id, state in list(self.pizza_states.items()):
            if (state["status"] == "in_zone" and
                track_id not in current_tracks_in_zone and
                track_id in current_tracks_detected):

                self.pizza_states[track_id]["status"] = "pending_dispatch"
                self.pizza_states[track_id]["exit_time"] = current_timestamp
                self.sales_counts[cam_id]["pending_dispatch"] += 1
                print(f"üö™ Pizza #{track_id} left zone - pending dispatch")

        # Check for dispatched pizzas
        for track_id, state in list(self.pizza_states.items()):
            if state["status"] == "pending_dispatch" and state["exit_time"] is not None:
                time_since_exit = current_timestamp - state["exit_time"]

                if time_since_exit >= self.dispatch_threshold:
                    self.pizza_states[track_id]["status"] = "dispatched"
                    self.sales_counts[cam_id]["total_sales"] += 1
                    self.sales_counts[cam_id]["pending_dispatch"] -= 1
                    print(f"üí∞ SALE! Pizza #{track_id} dispatched - Total: {self.sales_counts[cam_id]['total_sales']}")

        self.sales_counts[cam_id]["current_in_zone"] = len(current_tracks_in_zone)

        return len(current_tracks_in_zone), self.sales_counts[cam_id]["total_sales"], self.sales_counts[cam_id]["pending_dispatch"]

    def draw_simple_annotations(self, frame, tracked_detections, zone_polygon, pizzas_in_zone, total_sales, pending_dispatch, cam_id):
        """Simple annotation without supervision library"""
        annotated_frame = frame.copy()

        # Draw zone polygon
        cv2.polylines(annotated_frame, [zone_polygon.astype(np.int32)], True, (0, 255, 0), 3)

        # Draw tracked detections
        for detection in tracked_detections:
            track_id = detection["track_id"]
            bbox = detection["bbox"]
            center = detection["center"]

            x1, y1, x2, y2 = bbox.astype(int)

            # Determine color based on zone status
            if track_id in self.pizza_states:
                status = self.pizza_states[track_id]["status"]
                if status == "in_zone":
                    color = (0, 255, 0)  # Green
                    label = f"Pizza #{track_id} (In Zone)"
                elif status == "pending_dispatch":
                    color = (0, 165, 255)  # Orange
                    label = f"Pizza #{track_id} (Pending)"
                else:
                    color = (255, 0, 0)  # Blue
                    label = f"Pizza #{track_id}"
            else:
                color = (255, 255, 255)  # White
                label = f"Pizza #{track_id}"

            # Draw bounding box
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # Draw label
            cv2.putText(annotated_frame, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

            # Draw center point
            cv2.circle(annotated_frame, (int(center[0]), int(center[1])), 5, color, -1)

        # Draw status information
        cv2.putText(annotated_frame, f"SALES COUNT: {total_sales}",
                   (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
        cv2.putText(annotated_frame, f"In Zone: {pizzas_in_zone}",
                   (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Pending: {pending_dispatch}",
                   (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 165, 0), 2)
        cv2.putText(annotated_frame, f"Active Tracks: {len(tracked_detections)}",
                   (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"Camera: {cam_id}",
                   (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)

        return annotated_frame

    def process_frame(self, cam_id, frame, current_timestamp):
        """Process single frame"""
        self.frame_count += 1

        # Run YOLO detection
        results = self.model(frame, conf=self.confidence_threshold, verbose=False)[0]

        # Convert to simple format - FIXED
        if hasattr(results, 'boxes') and len(results.boxes) > 0:
            detections_data = type('obj', (object,), {
                'xyxy': results.boxes.xyxy.cpu().numpy(),
                'confidence': results.boxes.conf.cpu().numpy()
            })()
        else:
            detections_data = type('obj', (object,), {
                'xyxy': np.empty((0, 4)),
                'confidence': np.empty(0)
            })()

        # Simple tracking
        tracked_detections = self.simple_tracking(detections_data)

        # Get zone polygon
        zone_polygon = self.camera_configs[cam_id]['zone_polygon']

        # Update sales tracking
        pizzas_in_zone, total_sales, pending_dispatch = self.update_pizza_sales_tracking(
            cam_id, tracked_detections, zone_polygon, current_timestamp
        )

        # Draw annotations
        annotated_frame = self.draw_simple_annotations(
            frame, tracked_detections, zone_polygon,
            pizzas_in_zone, total_sales, pending_dispatch, cam_id
        )

        return annotated_frame, pizzas_in_zone, total_sales

    def process_partial_video(self, cam_id, max_frames=3000, start_frame=0):
        """Process partial video"""
        config = self.camera_configs[cam_id]

        print(f"üçï Starting FIXED SIMPLIFIED SALES TRACKING for {cam_id}")
        print(f"üìä Dispatch threshold: {self.dispatch_threshold/60:.1f} minutes")

        # Reset state
        self.active_tracks = {}
        self.pizza_states = {}
        self.sales_counts[cam_id] = {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0}
        self.frame_count = start_frame
        self.next_track_id = 1

        # Open video
        cap = cv2.VideoCapture(config['source_video_path'])
        if not cap.isOpened():
            print(f"Error: Cannot open video {config['source_video_path']}")
            return None

        # Get video properties
        self.fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        print(f"  Fixed simplified tracking enabled with {self.fps} FPS")

        # Jump to start frame
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        # Setup video writer
        output_path = config['target_video_path'].replace(
            '.mp4', f'_fixed_sales_{start_frame}to{start_frame+max_frames}.mp4'
        )
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, self.fps, (width, height))

        frame_count = 0

        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break

            current_timestamp = (start_frame + frame_count) / self.fps

            processed_frame, pizzas_in_zone, total_sales = self.process_frame(cam_id, frame, current_timestamp)

            out.write(processed_frame)

            frame_count += 1
            if frame_count % 300 == 0:
                progress = (frame_count / max_frames) * 100
                print(f"  üìà {cam_id}: {progress:.1f}% - Sales: {total_sales}, In Zone: {pizzas_in_zone}, Active Tracks: {len(self.active_tracks)}")

        # Cleanup
        cap.release()
        out.release()

        final_sales = self.sales_counts[cam_id]["total_sales"]

        print(f"‚úÖ {cam_id} FIXED TRACKING COMPLETED!")
        print(f"üèÜ FINAL SALES COUNT: {final_sales}")
        print(f"üìπ Output: {os.path.basename(output_path)}")

        return final_sales

    def generate_sales_report(self):
        """Generate sales report"""
        print("\n" + "="*60)
        print("üçï PIZZA SALES REPORT")
        print("="*60)

        total_sales_all_stores = 0

        for cam_id, sales_data in self.sales_counts.items():
            total_sales = sales_data["total_sales"]
            total_sales_all_stores += total_sales

            print(f"\nüìç {cam_id}:")
            print(f"  üí∞ Total Sales: {total_sales}")
            print(f"  üçï Currently in Zone: {sales_data['current_in_zone']}")
            print(f"  ‚è≥ Pending Dispatch: {sales_data['pending_dispatch']}")

        print(f"\nüèÜ TOTAL SALES ACROSS ALL STORES: {total_sales_all_stores}")
        print(f"üíµ Revenue Estimate: ${total_sales_all_stores * 15:.2f}")
        print("="*60)



# T·∫°o fixed processor
sales_processor = SalesTrackingProcessor(CAMERA_CONFIGS, model)

# Test v·ªõi fixed tracking
final_sales = sales_processor.process_partial_video("CAM_01", max_frames=10000, start_frame=4000)

# Generate report
sales_processor.generate_sales_report()






# Test v·ªõi confidence th·∫•p
sales_processor.confidence_threshold = 0.1  # Thay v√¨ 0.25

# Ch·∫°y test
final_sales = sales_processor.process_partial_video("CAM_01", max_frames=10000, start_frame=6000)






class ZoneBasedSpatialProcessor:
    def __init__(self, camera_configs, model):
        self.camera_configs = camera_configs
        self.model = model

        # Zone-first approach
        self.grid_size = 120
        self.spatial_memory = {}  # Only for pizzas IN ZONE
        self.pizza_states = {}
        self.sales_counts = {cam: {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0} for cam in camera_configs}
        self.dispatch_threshold = 120

        self.spatial_id_counter = 1
        self.frame_count = 0
        self.fps = 30

    def get_grid_key(self, center_x, center_y):
        """Convert coordinates to grid key"""
        grid_x = int(center_x // self.grid_size)
        grid_y = int(center_y // self.grid_size)
        return f"{grid_x}_{grid_y}"

    def is_in_zone(self, center_point, zone_polygon):
        """Check if point is inside zone"""
        return cv2.pointPolygonTest(zone_polygon, center_point, False) >= 0

    def zone_filtered_spatial_tracking(self, detections, zone_polygon, current_timestamp):
        """FIXED: Only track pizzas INSIDE the zone"""

        # Clean up expired spatial memories
        expired_grids = []
        for grid_key, memory in self.spatial_memory.items():
            frames_since_seen = self.frame_count - memory["last_seen"]
            if frames_since_seen > 180:  # 6 seconds
                expired_grids.append(grid_key)

        for grid_key in expired_grids:
            del self.spatial_memory[grid_key]

        if not hasattr(detections, 'xyxy') or len(detections.xyxy) == 0:
            return []

        bboxes = detections.xyxy
        confidences = detections.confidence

        zone_detections = []  # Only detections IN ZONE

        # STEP 1: Filter detections by zone FIRST
        for i, (bbox, conf) in enumerate(zip(bboxes, confidences)):
            if conf < 0.15:
                continue

            x1, y1, x2, y2 = bbox
            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2
            center = (center_x, center_y)

            # CRITICAL: Only process if pizza is IN ZONE
            if not self.is_in_zone(center, zone_polygon):
                continue  # Skip pizzas outside zone

            grid_key = self.get_grid_key(center_x, center_y)

            # STEP 2: Find or create spatial ID for zone detections
            spatial_id = self.find_zone_spatial_id(center_x, center_y, grid_key)

            # STEP 3: Update spatial memory (only for zone detections)
            self.spatial_memory[grid_key] = {
                "spatial_id": spatial_id,
                "bbox": bbox,
                "center": center,
                "last_seen": self.frame_count,
                "last_timestamp": current_timestamp
            }

            zone_detections.append({
                "spatial_id": spatial_id,
                "center": center,
                "bbox": bbox,
                "confidence": conf,
                "grid_key": grid_key
            })

        return zone_detections

    def find_zone_spatial_id(self, center_x, center_y, grid_key):
        """Find spatial ID with robust matching for zone detections"""

        # Check exact grid
        if grid_key in self.spatial_memory:
            memory = self.spatial_memory[grid_key]
            frames_since_seen = self.frame_count - memory["last_seen"]
            if frames_since_seen <= 180:
                return memory["spatial_id"]

        # Check neighboring grids
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                parts = grid_key.split('_')
                grid_x, grid_y = int(parts[0]), int(parts[1])
                neighbor_key = f"{grid_x + dx}_{grid_y + dy}"

                if neighbor_key in self.spatial_memory:
                    memory = self.spatial_memory[neighbor_key]
                    frames_since_seen = self.frame_count - memory["last_seen"]

                    if frames_since_seen <= 180:
                        # Calculate distance
                        old_bbox = memory["bbox"]
                        old_center_x = (old_bbox[0] + old_bbox[2]) / 2
                        old_center_y = (old_bbox[1] + old_bbox[3]) / 2

                        distance = np.sqrt((center_x - old_center_x)**2 + (center_y - old_center_y)**2)

                        if distance <= 150:  # Merge threshold
                            spatial_id = memory["spatial_id"]
                            del self.spatial_memory[neighbor_key]
                            return spatial_id

        # Create new spatial ID
        new_id = self.spatial_id_counter
        self.spatial_id_counter += 1
        print(f"üÜï New Pizza Spatial ID #{new_id} entered staging zone at grid {grid_key}")
        return new_id

    def update_zone_sales_tracking(self, cam_id, zone_detections, current_timestamp):
        """Sales tracking for zone-filtered detections"""
        current_spatial_ids = set()

        # All detections are already IN ZONE (pre-filtered)
        for detection in zone_detections:
            spatial_id = detection["spatial_id"]
            current_spatial_ids.add(spatial_id)

            # Pizza in zone
            if spatial_id not in self.pizza_states:
                self.pizza_states[spatial_id] = {
                    "status": "in_zone",
                    "enter_time": current_timestamp,
                    "exit_time": None,
                    "cam_id": cam_id
                }
                print(f"üçï Pizza Spatial #{spatial_id} entered staging zone at {current_timestamp:.1f}s")

            # Pizza returned to zone
            elif self.pizza_states[spatial_id]["status"] == "pending_dispatch":
                self.pizza_states[spatial_id]["status"] = "in_zone"
                self.pizza_states[spatial_id]["exit_time"] = None
                self.sales_counts[cam_id]["pending_dispatch"] -= 1
                print(f"‚Ü©Ô∏è Pizza Spatial #{spatial_id} returned to zone - dispatch cancelled")

        # Check for pizzas that left the zone (not detected in current frame)
        for spatial_id, state in list(self.pizza_states.items()):
            if (state["status"] == "in_zone" and
                spatial_id not in current_spatial_ids):

                # Pizza left zone
                self.pizza_states[spatial_id]["status"] = "pending_dispatch"
                self.pizza_states[spatial_id]["exit_time"] = current_timestamp
                self.sales_counts[cam_id]["pending_dispatch"] += 1
                print(f"üö™ Pizza Spatial #{spatial_id} left zone - pending dispatch (30s timer)")

        # Check for dispatched pizzas
        for spatial_id, state in list(self.pizza_states.items()):
            if state["status"] == "pending_dispatch" and state["exit_time"] is not None:
                time_since_exit = current_timestamp - state["exit_time"]

                if time_since_exit >= self.dispatch_threshold:
                    self.pizza_states[spatial_id]["status"] = "dispatched"
                    self.sales_counts[cam_id]["total_sales"] += 1
                    self.sales_counts[cam_id]["pending_dispatch"] -= 1
                    print(f"üí∞ SALE! Pizza Spatial #{spatial_id} dispatched after {time_since_exit:.1f}s - Total: {self.sales_counts[cam_id]['total_sales']}")

        self.sales_counts[cam_id]["current_in_zone"] = len(current_spatial_ids)

        return len(current_spatial_ids), self.sales_counts[cam_id]["total_sales"], self.sales_counts[cam_id]["pending_dispatch"]

    def draw_zone_annotations(self, frame, zone_detections, zone_polygon, pizzas_in_zone, total_sales, pending_dispatch, cam_id):
        """Enhanced visualization showing only zone detections"""
        annotated_frame = frame.copy()

        # Draw zone polygon prominently
        cv2.polylines(annotated_frame, [zone_polygon.astype(np.int32)], True, (0, 255, 0), 4)

        # Fill zone with semi-transparent overlay
        overlay = annotated_frame.copy()
        cv2.fillPoly(overlay, [zone_polygon.astype(np.int32)], (0, 255, 0))
        cv2.addWeighted(annotated_frame, 0.9, overlay, 0.1, 0, annotated_frame)

        # Draw only zone detections
        for detection in zone_detections:
            spatial_id = detection["spatial_id"]
            bbox = detection["bbox"]
            center = detection["center"]

            x1, y1, x2, y2 = bbox.astype(int)

            # Color based on status
            if spatial_id in self.pizza_states:
                status = self.pizza_states[spatial_id]["status"]
                if status == "in_zone":
                    color = (0, 255, 0)  # Green
                    label = f"Zone Pizza #{spatial_id}"
                elif status == "pending_dispatch":
                    time_left = self.dispatch_threshold - (self.frame_count/self.fps - self.pizza_states[spatial_id]["exit_time"])
                    color = (0, 165, 255)  # Orange
                    label = f"Pizza #{spatial_id} (Dispatch: {time_left:.0f}s)"
                else:
                    color = (255, 0, 0)  # Blue
                    label = f"Pizza #{spatial_id}"
            else:
                color = (0, 255, 0)  # Green for new zone detections
                label = f"Zone Pizza #{spatial_id}"

            # Draw bounding box
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 3)

            # Draw label
            cv2.putText(annotated_frame, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            # Draw center point
            cv2.circle(annotated_frame, (int(center[0]), int(center[1])), 6, color, -1)

        # Status display
        cv2.putText(annotated_frame, f"SALES COUNT: {total_sales}",
                   (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
        cv2.putText(annotated_frame, f"In Zone: {pizzas_in_zone}",
                   (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Pending: {pending_dispatch}",
                   (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 165, 0), 2)
        cv2.putText(annotated_frame, f"Zone Spatial IDs: {len(self.spatial_memory)}",
                   (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"ZONE-BASED TRACKING",
                   (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        return annotated_frame

    def process_frame(self, cam_id, frame, current_timestamp):
        """Process frame with zone-first spatial tracking"""
        self.frame_count += 1

        # YOLO detection
        results = self.model(frame, conf=0.15, verbose=False)[0]

        if hasattr(results, 'boxes') and len(results.boxes) > 0:
            detections_data = type('obj', (object,), {
                'xyxy': results.boxes.xyxy.cpu().numpy(),
                'confidence': results.boxes.conf.cpu().numpy()
            })()
        else:
            detections_data = type('obj', (object,), {
                'xyxy': np.empty((0, 4)),
                'confidence': np.empty(0)
            })()

        # Get zone polygon
        zone_polygon = self.camera_configs[cam_id]['zone_polygon']

        # Zone-filtered spatial tracking
        zone_detections = self.zone_filtered_spatial_tracking(detections_data, zone_polygon, current_timestamp)

        # Sales tracking
        pizzas_in_zone, total_sales, pending_dispatch = self.update_zone_sales_tracking(
            cam_id, zone_detections, current_timestamp
        )

        # Annotations
        annotated_frame = self.draw_zone_annotations(
            frame, zone_detections, zone_polygon,
            pizzas_in_zone, total_sales, pending_dispatch, cam_id
        )

        return annotated_frame, pizzas_in_zone, total_sales

    def process_partial_video(self, cam_id, max_frames=3000, start_frame=0):
        """Process video with zone-based spatial tracking"""
        config = self.camera_configs[cam_id]

        print(f"üçï Starting ZONE-BASED SPATIAL TRACKING for {cam_id}")
        print(f"üìä Dispatch threshold: {self.dispatch_threshold} seconds")
        print(f"üî≤ Grid size: {self.grid_size} pixels")
        print(f"üéØ ONLY tracking pizzas INSIDE staging zone")

        # Reset state
        self.spatial_memory = {}
        self.pizza_states = {}
        self.sales_counts[cam_id] = {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0}
        self.frame_count = start_frame
        self.spatial_id_counter = 1

        # Open video
        cap = cv2.VideoCapture(config['source_video_path'])
        if not cap.isOpened():
            print(f"Error: Cannot open video {config['source_video_path']}")
            return None

        # Video properties
        self.fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        print(f"  Zone-based tracking enabled with {self.fps} FPS")

        # Jump to start frame
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        # Video writer
        output_path = config['target_video_path'].replace(
            '.mp4', f'_zone_based_{start_frame}to{start_frame+max_frames}.mp4'
        )
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, self.fps, (width, height))

        frame_count = 0

        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break

            current_timestamp = (start_frame + frame_count) / self.fps

            processed_frame, pizzas_in_zone, total_sales = self.process_frame(cam_id, frame, current_timestamp)

            out.write(processed_frame)

            frame_count += 1
            if frame_count % 300 == 0:
                progress = (frame_count / max_frames) * 100
                print(f"  üìà {cam_id}: {progress:.1f}% - Sales: {total_sales}, In Zone: {pizzas_in_zone}, Zone IDs: {len(self.spatial_memory)}")

        # Final dispatch check
        final_timestamp = (start_frame + frame_count) / self.fps
        for spatial_id, state in list(self.pizza_states.items()):
            if state["status"] == "pending_dispatch" and state["exit_time"] is not None:
                time_since_exit = final_timestamp - state["exit_time"]
                if time_since_exit >= self.dispatch_threshold:
                    self.sales_counts[cam_id]["total_sales"] += 1
                    print(f"üí∞ FINAL SALE! Pizza Spatial #{spatial_id} dispatched at video end")

        # Cleanup
        cap.release()
        out.release()

        final_sales = self.sales_counts[cam_id]["total_sales"]

        print(f"‚úÖ {cam_id} ZONE-BASED TRACKING COMPLETED!")
        print(f"üèÜ FINAL SALES COUNT: {final_sales}")
        print(f"üéØ Total Zone Spatial IDs Created: {self.spatial_id_counter - 1}")
        print(f"üìπ Output: {os.path.basename(output_path)}")

        return final_sales

    def generate_sales_report(self):
        """Generate sales report"""
        print("\n" + "="*60)
        print("üçï ZONE-BASED PIZZA SALES REPORT")
        print("="*60)

        total_sales_all_stores = 0

        for cam_id, sales_data in self.sales_counts.items():
            total_sales = sales_data["total_sales"]
            total_sales_all_stores += total_sales

            print(f"\nüìç {cam_id}:")
            print(f"  üí∞ Total Sales: {total_sales}")
            print(f"  üçï Currently in Zone: {sales_data['current_in_zone']}")
            print(f"  ‚è≥ Pending Dispatch: {sales_data['pending_dispatch']}")

        print(f"\nüèÜ TOTAL SALES ACROSS ALL STORES: {total_sales_all_stores}")
        print(f"üíµ Revenue Estimate: ${total_sales_all_stores * 15:.2f}")
        print("="*60)



# T·∫°o zone-based processor (NEW)
zone_processor = ZoneBasedSpatialProcessor(CAMERA_CONFIGS, model)

# Test v·ªõi zone-first tracking
final_sales = zone_processor.process_partial_video("CAM_01", max_frames=10000, start_frame=6000)

# Generate report
zone_processor.generate_sales_report()






# Initialized device
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {DEVICE}")

# Load model v2
model_path = "/content/drive/MyDrive/pizza_project/training_results/pizza_detector_v2_stable/weights/best.pt"
model = YOLO(model_path)
model.to(DEVICE)



# Print metrics
print("=== MODEL INFORMATION ===")
print(f"Model: {model.model}")
print(f"Device: {DEVICE}")
print(f"Model summary: {model.info()}")



print("Model loaded successfully!")






class RobustZoneProcessor:
    def __init__(self, camera_configs, model):
        self.camera_configs = camera_configs
        self.model = model

        # --- Probation System ---
        self.potential_pizzas = {}  # {grid_key: {"frames_seen": int, "first_seen": ts, "bbox": bbox}}
        self.min_frames_for_confirmation = 30  # Must be seen for 30 frames (~0.16s) to be confirmed

        # --- Core System ---
        self.grid_size = 120
        self.spatial_memory = {}
        self.pizza_states = {}
        self.sales_counts = {cam: {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0} for cam in camera_configs}
        self.dispatch_threshold = 90

        self.spatial_id_counter = 1
        self.frame_count = 0
        self.fps = 30

    def get_grid_key(self, center_x, center_y):
        """Convert coordinates to grid key"""
        return f"{int(center_x // self.grid_size)}_{int(center_y // self.grid_size)}"

    def is_in_zone(self, center_point, zone_polygon):
        """Check if point is inside zone"""
        return cv2.pointPolygonTest(zone_polygon, center_point, False) >= 0

    def robust_zone_tracking(self, detections, zone_polygon, current_timestamp):
        """
        The core of the solution: A robust tracking system with a probation period
        to eliminate ghost detections.
        """

        # --- Cleanup ---
        # 1. Clean up old potential pizzas
        expired_potentials = [k for k, v in self.potential_pizzas.items() if self.frame_count - v["last_seen_frame"] > self.min_frames_for_confirmation + 2]
        for k in expired_potentials:
            del self.potential_pizzas[k]

        # 2. Clean up old confirmed spatial memories
        expired_confirmed = [k for k, v in self.spatial_memory.items() if self.frame_count - v["last_seen"] > 180]
        for k in expired_confirmed:
            del self.spatial_memory[k]

        # --- Processing ---
        if not hasattr(detections, 'xyxy') or len(detections.xyxy) == 0:
            return [], [] # Return empty lists for confirmed and potential detections

        bboxes = detections.xyxy
        confidences = detections.confidence

        confirmed_detections = []
        potential_detections = []

        unmatched_detections = list(range(len(bboxes)))

        # --- Step 1: Match detections to existing CONFIRMED pizzas ---
        for grid_key, memory in list(self.spatial_memory.items()):
            best_match_idx = -1
            best_dist = float('inf')

            for i in unmatched_detections:
                x1, y1, x2, y2 = bboxes[i]
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2

                dist = np.sqrt((center_x - memory["center"][0])**2 + (center_y - memory["center"][1])**2)

                if dist < 150 and dist < best_dist:
                    best_dist = dist
                    best_match_idx = i

            if best_match_idx != -1:
                # Update confirmed pizza
                x1, y1, x2, y2 = bboxes[best_match_idx]
                new_center = ((x1+x2)/2, (y1+y2)/2)
                new_grid_key = self.get_grid_key(new_center[0], new_center[1])

                # Move memory to new grid if needed
                if new_grid_key != grid_key:
                    del self.spatial_memory[grid_key]

                memory["bbox"] = bboxes[best_match_idx]
                memory["center"] = new_center
                memory["last_seen"] = self.frame_count
                self.spatial_memory[new_grid_key] = memory

                confirmed_detections.append(memory)
                unmatched_detections.remove(best_match_idx)

        # --- Step 2: Process remaining detections as POTENTIAL pizzas ---
        new_potentials_this_frame = {}
        for i in unmatched_detections:
            bbox = bboxes[i]
            conf = confidences[i]

            if conf < 0.2: continue # Stricter confidence for new objects

            center = ((bbox[0]+bbox[2])/2, (bbox[1]+bbox[3])/2)

            if not self.is_in_zone(center, zone_polygon): continue

            grid_key = self.get_grid_key(center[0], center[1])

            # Match with a potential pizza from last frame
            matched_potential = False
            for old_grid, pot in list(self.potential_pizzas.items()):
                dist = np.sqrt((center[0] - pot["center"][0])**2 + (center[1] - pot["center"][1])**2)
                if dist < 100: # Match potential
                    pot["frames_seen"] += 1
                    pot["center"] = center
                    pot["last_seen_frame"] = self.frame_count

                    if pot["frames_seen"] >= self.min_frames_for_confirmation:
                        # --- GRADUATION! Promote to confirmed pizza ---
                        new_id = self.spatial_id_counter
                        self.spatial_id_counter += 1

                        confirmed_memory = {
                            "spatial_id": new_id,
                            "bbox": bbox,
                            "center": center,
                            "last_seen": self.frame_count
                        }
                        self.spatial_memory[grid_key] = confirmed_memory
                        confirmed_detections.append(confirmed_memory)

                        print(f"‚úÖ CONFIRMED! Pizza Spatial ID #{new_id} at grid {grid_key} after {pot['frames_seen']} frames.")

                        # Remove from potential list
                        del self.potential_pizzas[old_grid]
                    else:
                        # Still on probation
                        potential_detections.append(pot)

                    matched_potential = True
                    break

            if not matched_potential:
                # First time seeing this potential pizza
                self.potential_pizzas[grid_key] = {
                    "frames_seen": 1,
                    "center": center,
                    "last_seen_frame": self.frame_count,
                    "bbox": bbox
                }
                potential_detections.append(self.potential_pizzas[grid_key])

        return confirmed_detections, potential_detections

    def update_sales_logic(self, cam_id, confirmed_detections, current_timestamp):
        """Sales logic now only works with CONFIRMED detections"""
        current_confirmed_ids = {d["spatial_id"] for d in confirmed_detections}

        # All confirmed detections are IN ZONE by definition
        for det in confirmed_detections:
            spatial_id = det["spatial_id"]
            if spatial_id not in self.pizza_states:
                self.pizza_states[spatial_id] = {"status": "in_zone", "enter_time": current_timestamp}
                print(f"üçï Confirmed Pizza #{spatial_id} now in staging zone.")
            elif self.pizza_states[spatial_id]["status"] == "pending_dispatch":
                self.pizza_states[spatial_id]["status"] = "in_zone"
                self.sales_counts[cam_id]["pending_dispatch"] -= 1
                print(f"‚Ü©Ô∏è Confirmed Pizza #{spatial_id} returned to zone.")

        # Check for confirmed pizzas that disappeared
        for spatial_id, state in list(self.pizza_states.items()):
            if state["status"] == "in_zone" and spatial_id not in current_confirmed_ids:
                state["status"] = "pending_dispatch"
                state["exit_time"] = current_timestamp
                self.sales_counts[cam_id]["pending_dispatch"] += 1
                print(f"üëª Confirmed Pizza #{spatial_id} disappeared. Starting 90s dispatch timer.")

        # Check for sales
        for spatial_id, state in list(self.pizza_states.items()):
            if state["status"] == "pending_dispatch" and current_timestamp - state["exit_time"] >= self.dispatch_threshold:
                state["status"] = "dispatched"
                self.sales_counts[cam_id]["total_sales"] += 1
                self.sales_counts[cam_id]["pending_dispatch"] -= 1
                print(f"üí∞ SALE! Pizza #{spatial_id} dispatched. Total Sales: {self.sales_counts[cam_id]['total_sales']}")

        self.sales_counts[cam_id]["current_in_zone"] = len(current_confirmed_ids)
        return len(current_confirmed_ids), self.sales_counts[cam_id]["total_sales"], self.sales_counts[cam_id]["pending_dispatch"]

    def draw_robust_annotations(self, frame, confirmed, potentials, zone_polygon, in_zone_count, sales_count, pending_count):
        """Visualize confirmed (green) and potential (yellow) pizzas"""
        annotated_frame = frame.copy()
        cv2.polylines(annotated_frame, [zone_polygon.astype(np.int32)], True, (0, 255, 0), 2)

        # Draw CONFIRMED pizzas (Green)
        for det in confirmed:
            x1, y1, x2, y2 = det["bbox"].astype(int)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
            cv2.putText(annotated_frame, f"Confirmed #{det['spatial_id']}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Draw POTENTIAL pizzas (Yellow)
        for det in potentials:
            x1, y1, x2, y2 = det["bbox"].astype(int)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
            cv2.putText(annotated_frame, f"Potential ({det['frames_seen']}/{self.min_frames_for_confirmation})", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # Status text
        cv2.putText(annotated_frame, f"SALES: {sales_count}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
        cv2.putText(annotated_frame, f"In Zone (Confirmed): {in_zone_count}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Pending Dispatch: {pending_count}", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 165, 0), 2)
        cv2.putText(annotated_frame, f"Potential Pizzas: {len(potentials)}", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

        return annotated_frame

    def process_frame(self, cam_id, frame, current_timestamp):
        """Process frame with robust logic"""
        self.frame_count += 1

        results = self.model(frame, conf=0.15, verbose=False)[0]

        detections_data = type('obj', (object,), {
            'xyxy': results.boxes.xyxy.cpu().numpy() if hasattr(results, 'boxes') and len(results.boxes) > 0 else np.empty((0, 4)),
            'confidence': results.boxes.conf.cpu().numpy() if hasattr(results, 'boxes') and len(results.boxes) > 0 else np.empty(0)
        })()

        zone_polygon = self.camera_configs[cam_id]['zone_polygon']

        # Robust tracking
        confirmed_detections, potential_detections = self.robust_zone_tracking(detections_data, zone_polygon, current_timestamp)

        # Sales logic on confirmed detections only
        pizzas_in_zone, total_sales, pending_dispatch = self.update_sales_logic(cam_id, confirmed_detections, current_timestamp)

        # Annotations
        annotated_frame = self.draw_robust_annotations(frame, confirmed_detections, potential_detections, zone_polygon, pizzas_in_zone, total_sales, pending_dispatch)

        return annotated_frame

    def process_partial_video(self, cam_id, max_frames=3000, start_frame=0):
        """Process video with robust, probation-based logic"""
        config = self.camera_configs[cam_id]

        print(f"üçï Starting ROBUST PROBATION-BASED TRACKING for {cam_id}")

        # Reset state
        self.potential_pizzas = {}
        self.spatial_memory = {}
        self.pizza_states = {}
        self.sales_counts[cam_id] = {"total_sales": 0, "current_in_zone": 0, "pending_dispatch": 0}
        self.frame_count = start_frame
        self.spatial_id_counter = 1

        cap = cv2.VideoCapture(config['source_video_path'])
        self.fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        output_path = config['target_video_path'].replace('.mp4', f'_robust_{start_frame}to{start_frame+max_frames}.mp4')
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), self.fps, (width, height))

        frame_idx = 0
        while frame_idx < max_frames:
            ret, frame = cap.read()
            if not ret: break

            current_timestamp = (start_frame + frame_idx) / self.fps
            processed_frame = self.process_frame(cam_id, frame, current_timestamp)
            out.write(processed_frame)

            frame_idx += 1
            if frame_idx % 300 == 0:
                print(f"  üìà Frame {start_frame + frame_idx}: Sales: {self.sales_counts[cam_id]['total_sales']}, Confirmed: {self.sales_counts[cam_id]['current_in_zone']}, Potentials: {len(self.potential_pizzas)}")

        # Final dispatch check
        final_timestamp = (start_frame + frame_idx) / self.fps
        for spatial_id, state in list(self.pizza_states.items()):
            if state["status"] == "pending_dispatch" and final_timestamp - state["exit_time"] >= self.dispatch_threshold:
                self.sales_counts[cam_id]["total_sales"] += 1
                print(f"üí∞ FINAL SALE! Pizza #{spatial_id} dispatched.")

        cap.release()
        out.release()

        final_sales = self.sales_counts[cam_id]["total_sales"]
        print(f"‚úÖ ROBUST TRACKING COMPLETED! Final Sales: {final_sales}")
        return final_sales

    def generate_sales_report(self):
        """Generate final sales report"""
        print("\n" + "="*60)
        print("üçï ROBUST PIZZA SALES REPORT")
        print("="*60)

        total_sales_all_stores = 0
        for cam_id, sales_data in self.sales_counts.items():
            total_sales = sales_data.get("total_sales", 0)
            total_sales_all_stores += total_sales
            print(f"\nüìç {cam_id}: Total Sales = {total_sales}")

        print(f"\nüèÜ TOTAL SALES ACROSS ALL STORES: {total_sales_all_stores}")
        print("="*60)



# Created processor with probation system
robust_processor = RobustZoneProcessor(CAMERA_CONFIGS, model)

# Test with probation-based tracking
final_sales = robust_processor.process_partial_video("CAM_01", max_frames=10000, start_frame=6000)

# Generate report
robust_processor.generate_sales_report()




